{"cells":[{"cell_type":"markdown","metadata":{},"source":[" # Homework 5 "]},{"cell_type":"markdown","metadata":{},"source":[" ### 2 . CIFAR10 - Classification "]},{"cell_type":"markdown","metadata":{},"source":["The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n","\n","Feature structure: \n","id: Text(dtype=object)\n","image: Image(shape=(32,32,3), dtype=uint8)\n","label: ClassLabel(dtype=int64, num_classes=10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import tensorflow_datasets as tfds\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from matplotlib import image\n","import numpy as np\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["(train_ds, test_ds), ds_info = tfds.load('cifar10', split=['train', 'test'], as_supervised=True, with_info = True)\n","#print(ds_info)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def prepare_cifar10_data(cifar, batchsize = 32):\n","  '''\n","  This function prepares the dataset for usage in a learning model\n","\n","  Args:\n","  cifar --- The cifar-10 dataset \n","  batchsize --- The batch size (default:32)\n","\n","  '''\n","  #convert data from uint8 to float32 \n","  cifar = cifar.map(lambda img, target: (tf.cast(img, tf.float32), target))\n","  #sloppy input normalization, just bringing image values from range [0, 255] to [-1, 1]\n","  cifar = cifar.map(lambda img, target: ((img/128.)-1., target))\n","  #create one-hot targets\n","  cifar = cifar.map(lambda img, target: (img, tf.one_hot(target, depth=10)))\n","  #cache this progress in memory\n","  cifar = cifar.cache()\n","  #shuffle, batch, prefetch\n","  cifar = cifar.shuffle(1000)\n","  cifar = cifar.batch(32)\n","  cifar= cifar.prefetch(tf.data.AUTOTUNE)\n","  #return preprocessed dataset\n","  return cifar\n","\n","\n","train_dataset = train_ds.apply(prepare_cifar10_data)\n","test_dataset = test_ds.apply(prepare_cifar10_data)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tfds.visualization.show_examples(test_ds, ds_info)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ConvModel(tf.keras.model):\n","    def __init__(self, layers, optimizer):\n","        super().__init__()\n","\n","        self.loss_function = tf.keras.losses.CategoricalCrossentropy()\n","        self.optimizer = optimizer\n","\n","        self.layers = layers\n","        self.out = tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n","\n","        # instantiate metric objects to keep track of the training/test loss and accuracy\n","        self.loss_metric = tf.keras.metrics.Mean(name=\"loss\") \n","        self.accuracy_metric = tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3.7.13 ('iannwtf')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"1290a8c9e4f9d619e02c129e82eb2a58b00cf218ca683fba6d26250ac174955c"}}},"nbformat":4,"nbformat_minor":2}
